"""
Entity extraction - extract cities, regions, counts from text.
Uses centralized patterns and priority-based matching.
"""
import re
from typing import List, Optional
from dataclasses import dataclass
import logging

from .patterns import PATTERNS
from .normalize import normalize_city, normalize_region, extract_region_from_alias, is_skip_word
from core.constants import CITIES, REGION_ALIASES, CHANNEL_REGIONS
from utils.geo import get_region_for_city

REGION_ALIASES_LOWER = {k.lower() for k in REGION_ALIASES}
SUMMARY_COUNT_RE = re.compile(r'^\s*[–ê-–Ø–Ü–á–Ñ“ê–∞-—è—ñ—ó—î“ë\s]+‚Äî\s*\d+—Ö\s*$')
SUMMARY_HEADER_RE = re.compile(r'^\s*–ü–æ\s+–ë–ø–õ–ê\b', re.IGNORECASE)
SPECIAL_ATTENTION_RE = re.compile(r'^–û—Å–æ–±–ª–∏–≤–∞\s+—É–≤–∞–≥–∞\s*:\s*(.*)$', re.IGNORECASE)
MAX_ATTENTION_ITEMS = 80

logger = logging.getLogger(__name__)


@dataclass
class ExtractedEntity:
    """Extracted location entity."""
    city: str
    region: str
    count: Optional[int] = None
    confidence: float = 1.0
    pattern_name: str = ""


def extract_entities(text: str, channel: str = None) -> List[ExtractedEntity]:
    """
    Extract all location entities from text.
    
    Uses priority-based pattern matching:
    1. Most specific patterns first (city + region in parens)
    2. Region header patterns (sets context)
    3. City-only patterns (use context or geocoding)
    """
    if not text:
        return []
    
    entities = []
    current_region = CHANNEL_REGIONS.get(channel) if channel else None
    
    special_attention = False
    attention_buffer: List[str] = []

    for line in text.strip().split('\n'):
        line = line.strip()
        if not line:
            if special_attention and attention_buffer:
                cities_text = ', '.join(attention_buffer)
                entities.extend(_build_entities_from_city_list(
                    cities_text,
                    None,
                    None,
                    0.7,
                    'special_attention'
                ))
                attention_buffer = []
            special_attention = False
            continue
        
        if PATTERNS.skip['alerts'].search(line) or PATTERNS.skip['shelter'].search(line):
            continue

        # Skip regional summary counts like "–°—É–º—â–∏–Ω–∞ ‚Äî 1—Ö"
        if SUMMARY_COUNT_RE.match(line):
            continue
        if SUMMARY_HEADER_RE.match(line):
            continue

        # Parse "–û—Å–æ–±–ª–∏–≤–∞ —É–≤–∞–≥–∞" blocks with city list
        attention_match = SPECIAL_ATTENTION_RE.match(line)
        if attention_match:
            special_attention = True
            tail = attention_match.group(1).strip()
            if tail:
                attention_buffer.append(tail)
            continue
        if special_attention:
            attention_buffer.append(line)
            if len(attention_buffer) >= MAX_ATTENTION_ITEMS:
                cities_text = ', '.join(attention_buffer)
                entities.extend(_build_entities_from_city_list(
                    cities_text,
                    None,
                    None,
                    0.7,
                    'special_attention'
                ))
                attention_buffer = []
                special_attention = False
            continue
        
        inline_header = _extract_inline_region_header(line)
        if inline_header:
            current_region, line = inline_header

        header_match = _extract_region_header(line)
        if header_match:
            current_region = header_match
            continue

        entity = _extract_city_region_parens(line)
        if entity:
            entities.append(entity)
            continue

        entity = _extract_kursom_na_city_region(line)
        if entity:
            entities.append(entity)
            continue

        entity = _extract_city_region_alias_parens(line)
        if entity:
            entities.append(entity)
            continue
        
        region_cities = _extract_region_colon_cities(line, current_region)
        if region_cities:
            entities.extend(region_cities)
            continue
        
        # "‚úàÔ∏è City/—Ä-–Ω - –æ–±–µ—Ä–µ–∂–Ω–æ –ø–æ –ë–ü–õ–ê!" - extract city and geocode
        oberezhno_entities = _extract_oberezhno_bpla(line)
        if oberezhno_entities:
            entities.extend(oberezhno_entities)
            continue
        
        context_entities = _extract_with_context(line, current_region)
        if context_entities:
            entities.extend(context_entities)
            continue
        
        arrow_entities = _extract_arrow_city(line, current_region)
        if arrow_entities:
            entities.extend(arrow_entities)
    
    if special_attention and attention_buffer:
        cities_text = ', '.join(attention_buffer)
        entities.extend(_build_entities_from_city_list(
            cities_text,
            None,
            None,
            0.7,
            'special_attention'
        ))

    return [e for e in entities if _is_valid_entity(e)]


def _extract_region_header(line: str) -> Optional[str]:
    clean = re.sub(r'^[‚úàÔ∏èüõµüõ∏‚ö†Ô∏è‚ùóÔ∏èüî¥üì°\s]+', '', line).strip()
    match = re.match(r'^(\S+(?:\s+–æ–±–ª–∞—Å—Ç—å)?):?\s*$', clean, re.IGNORECASE)
    if match:
        region_name = match.group(1).strip().rstrip(':')
        if region_name in REGION_ALIASES:
            return REGION_ALIASES[region_name]
        if '–æ–±–ª–∞—Å—Ç' in region_name.lower():
            return normalize_region(region_name)
    return None


def _extract_inline_region_header(line: str) -> Optional[tuple]:
    clean = re.sub(r'^[‚úàÔ∏èüõµüõ∏‚ö†Ô∏è‚ùóÔ∏èüî¥üì°\s]+', '', line).strip()
    match = re.match(r'^(\S+(?:\s+–æ–±–ª–∞—Å—Ç—å)?):\s*(.+)$', clean, re.IGNORECASE)
    if not match:
        return None

    region_name = match.group(1).strip().rstrip(':')
    remainder = match.group(2).strip()
    region = REGION_ALIASES.get(region_name)
    if not region and '–æ–±–ª–∞—Å—Ç' in region_name.lower():
        region = normalize_region(region_name)
    if not region:
        return None
    return region, remainder


def _extract_city_region_parens(line: str) -> Optional[ExtractedEntity]:
    match = PATTERNS.location['city_region_parens'].search(line)
    if not match:
        return None
    
    city_raw = match.group(1).strip()
    region_raw = match.group(2).strip()
    
    city = _clean_city_name(city_raw)
    if not city or is_skip_word(city):
        return None
    
    if city in REGION_ALIASES:
        return None
    
    city = normalize_city(city)
    region = normalize_region(region_raw)
    if not region:
        return None
    
    return ExtractedEntity(
        city=city,
        region=region,
        confidence=0.95,
        pattern_name='city_region_parens'
    )


def _extract_kursom_na_city_region(line: str) -> Optional[ExtractedEntity]:
    """Extract from 'X –∫—É—Ä—Å–æ–º –Ω–∞ City (Region –æ–±–ª.)' format."""
    match = PATTERNS.location['kursom_na_city_region'].search(line)
    if not match:
        return None

    city_raw = match.group(1).strip()
    region_raw = match.group(2).strip()

    city = _clean_city_name(city_raw)
    if not city or is_skip_word(city):
        return None

    if city in REGION_ALIASES:
        return None

    city = normalize_city(city)
    region = normalize_region(region_raw)
    if not region:
        return None

    return ExtractedEntity(
        city=city,
        region=region,
        confidence=0.9,
        pattern_name='kursom_na_city_region'
    )


def _extract_city_region_alias_parens(line: str) -> Optional[ExtractedEntity]:
    match = PATTERNS.location['city_region_alias_parens'].search(line)
    if not match:
        return None

    city_raw = match.group(1).strip()
    region_raw = match.group(2).strip()

    city = _clean_city_name(city_raw)
    if not city or is_skip_word(city):
        return None

    city = normalize_city(city)
    region = normalize_region(region_raw) or extract_region_from_alias(region_raw)
    if not region:
        return None

    return ExtractedEntity(
        city=city,
        region=region,
        confidence=0.9,
        pattern_name='city_region_alias_parens'
    )


def _extract_region_colon_cities(line: str, default_region: str = None) -> List[ExtractedEntity]:
    match = PATTERNS.location['region_colon_cities'].search(line)
    if not match:
        return []
    
    region_name = match.group(1).strip()
    cities_part = match.group(2).strip()
    
    region = REGION_ALIASES.get(region_name)
    if not region and '–æ–±–ª–∞—Å—Ç' in region_name.lower():
        region = normalize_region(region_name)
    if not region:
        region = default_region
    if not region:
        return []
    
    entities = []
    for entry in re.split(r',\s*', cities_part):
        city = _extract_city_from_entry(entry)
        if city and not is_skip_word(city):
            city = normalize_city(city)
            entities.append(ExtractedEntity(
                city=city,
                region=region,
                confidence=0.9,
                pattern_name='region_colon_cities'
            ))
    
    return entities


def _extract_oberezhno_bpla(line: str) -> List[ExtractedEntity]:
    """Extract city from '‚úàÔ∏è City/—Ä-–Ω - –æ–±–µ—Ä–µ–∂–Ω–æ –ø–æ –ë–ü–õ–ê!' pattern."""
    match = PATTERNS.location['oberezhno_bpla'].search(line)
    if not match:
        return []
    
    city_raw = match.group(1).strip()
    city = _clean_city_name(city_raw)
    if not city or is_skip_word(city):
        return []
    
    city = normalize_city(city)
    
    # Get region from geo (CITIES + cache)
    region = get_region_for_city(city)
    if not region:
        return []
    
    return [ExtractedEntity(
        city=city,
        region=region,
        confidence=0.85,
        pattern_name='oberezhno_bpla'
    )]


def _extract_with_context(line: str, current_region: str) -> List[ExtractedEntity]:
    region = current_region or extract_region_from_alias(line)
    if not region:
        return []

    entities: List[ExtractedEntity] = []
    
    match = PATTERNS.location['from_city_to_city'].search(line)
    if match:
        count = int(match.group(1)) if match.group(1) else None
        cities_text = match.group(3)
        if cities_text:
            entities.extend(_build_entities_from_city_list(
                cities_text,
                region,
                count,
                0.85,
                'from_city_to_city'
            ))
            return entities
    
    match = PATTERNS.location['count_threat_na_city'].search(line)
    if match:
        count = int(match.group(1))
        cities_text = match.group(2)
        if cities_text:
            entities.extend(_build_entities_from_city_list(
                cities_text,
                region,
                count,
                0.85,
                'count_threat_na_city'
            ))
            return entities

    match = PATTERNS.location['count_na_city'].search(line)
    if match:
        count = int(match.group(1))
        cities_text = match.group(2)
        if cities_text:
            entities.extend(_build_entities_from_city_list(
                cities_text,
                region,
                count,
                0.8,
                'count_na_city'
            ))
            return entities

    match = PATTERNS.location['count_city'].search(line)
    if match:
        count = int(match.group(1))
        cities_text = match.group(2)
        if cities_text:
            entities.extend(_build_entities_from_city_list(
                cities_text,
                region,
                count,
                0.75,
                'count_city'
            ))
            return entities

    match = PATTERNS.location['kursom_na_city'].search(line)
    if match:
        cities_text = match.group(1)
        if cities_text:
            entities.extend(_build_entities_from_city_list(
                cities_text,
                region,
                None,
                0.75,
                'kursom_na_city'
            ))
            return entities

    match = PATTERNS.location['moves_to_city'].search(line)
    if match:
        cities_text = match.group(1)
        if cities_text:
            entities.extend(_build_entities_from_city_list(
                cities_text,
                region,
                None,
                0.75,
                'moves_to_city'
            ))
            return entities
    
    match = PATTERNS.location['bpla_kursom_na'].search(line)
    if match:
        cities_text = match.group(1)
        if cities_text:
            entities.extend(_build_entities_from_city_list(
                cities_text,
                region,
                None,
                0.85,
                'bpla_kursom_na'
            ))
            return entities
    
    # "‚úàÔ∏è City/—Ä-–Ω - –æ–±–µ—Ä–µ–∂–Ω–æ –ø–æ –ë–ü–õ–ê!"
    match = PATTERNS.location['oberezhno_bpla'].search(line)
    if match:
        cities_text = match.group(1)
        if cities_text:
            entities.extend(_build_entities_from_city_list(
                cities_text,
                region,
                None,
                0.85,
                'oberezhno_bpla'
            ))
            return entities
    
    match = PATTERNS.location['n_v_rayoni'].search(line)
    if match:
        count = int(match.group(1))
        cities_text = match.group(2)
        if cities_text:
            entities.extend(_build_entities_from_city_list(
                cities_text,
                region,
                count,
                0.8,
                'n_v_rayoni'
            ))
            return entities

    match = PATTERNS.location['threat_bilya_city'].search(line)
    if match:
        cities_text = match.group(1)
        if cities_text:
            entities.extend(_build_entities_from_city_list(
                cities_text,
                region,
                None,
                0.8,
                'threat_bilya_city'
            ))
            return entities

    match = PATTERNS.location['v_bik_city'].search(line)
    if match:
        cities_text = match.group(1)
        if cities_text:
            entities.extend(_build_entities_from_city_list(
                cities_text,
                region,
                None,
                0.75,
                'v_bik_city'
            ))
            return entities

    match = PATTERNS.location['v_rayoni_city'].search(line)
    if match:
        cities_text = match.group(1)
        if cities_text:
            entities.extend(_build_entities_from_city_list(
                cities_text,
                region,
                None,
                0.75,
                'v_rayoni_city'
            ))
            return entities

    match = PATTERNS.location['threat_nad_city'].search(line)
    if match:
        cities_text = match.group(1)
        if cities_text:
            entities.extend(_build_entities_from_city_list(
                cities_text,
                region,
                None,
                0.8,
                'threat_nad_city'
            ))
            return entities

    match = PATTERNS.location['po_shahedu_na'].search(line)
    if match:
        cities_text = match.group(1)
        if cities_text:
            entities.extend(_build_entities_from_city_list(
                cities_text,
                region,
                1,
                0.75,
                'po_shahedu_na'
            ))
            return entities

    match = PATTERNS.location['city_to_you'].search(line)
    if match:
        cities_text = match.group(1)
        if cities_text:
            entities.extend(_build_entities_from_city_list(
                cities_text,
                region,
                None,
                0.75,
                'city_to_you'
            ))
            return entities

    return entities


def _extract_arrow_city(line: str, current_region: str) -> List[ExtractedEntity]:
    region = current_region or extract_region_from_alias(line)
    if not region:
        return []
    
    match = PATTERNS.location['arrow_city'].match(line)
    if not match:
        arrow_index = max(line.rfind('‚Üí'), line.rfind('‚û°Ô∏è'))
        if arrow_index >= 0:
            content = line[arrow_index + 1:].strip()
        else:
            return []
    else:
        content = match.group(1).strip()
    
    if content in REGION_ALIASES:
        return []
    
    cities = _split_cities(content)
    entities: List[ExtractedEntity] = []
    for city in cities:
        city = _clean_city_name(city)
        if not city or is_skip_word(city):
            continue
        entities.append(ExtractedEntity(
            city=normalize_city(city),
            region=region,
            confidence=0.8,
            pattern_name='arrow_city'
        ))

    return entities


def _extract_city_from_entry(entry: str) -> Optional[str]:
    entry = entry.strip()
    
    match = re.match(r'^\d+\s+(?:–Ω–∞|–≤ —Ä–∞–π–æ–Ω—ñ|–±—ñ–ª—è|–ø–æ–≤–∑)\s+(.+?)$', entry, re.IGNORECASE)
    if match:
        return match.group(1).strip().rstrip('.,;')
    
    match = re.match(r'^\d+\s+([–ê-–Ø–Ü–á–Ñ“ê–∞-—è—ñ—ó—î“ë\'\-\s]+)$', entry, re.IGNORECASE)
    if match:
        return match.group(1).strip().rstrip('.,;')
    
    match = re.match(r'^\d+\s*—Ö?\s*—à–∞—Ö–µ–¥[—ñ–∏—ñ–≤]*\s+–Ω–∞\s+(.+?)$', entry, re.IGNORECASE)
    if match:
        return match.group(1).strip().rstrip('.,;')
    
    match = re.match(r'^(?:–ë–ø–õ–ê|–ë–ü–õ–ê)\s+–∫—É—Ä—Å–æ–º\s+–Ω–∞\s+(.+?)$', entry, re.IGNORECASE)
    if match:
        return match.group(1).strip().rstrip('.,;')

    match = re.match(r'^\d+\s+(?:–±—ñ–ª—è|–ø–æ–±–ª–∏–∑—É)\s+(.+?)$', entry, re.IGNORECASE)
    if match:
        return match.group(1).strip().rstrip('.,;')

    match = re.match(r'^(?:–∫—Ä—É–∂–ª—è—î|–∫—Ä—É—Ç–∏—Ç—å—Å—è)\s+–±—ñ–ª—è\s+(.+?)$', entry, re.IGNORECASE)
    if match:
        return match.group(1).strip().rstrip('.,;')

    match = re.match(r'^(?:—à–∞—Ö–µ–¥|–ë–ø–õ–ê|–ë–ü–õ–ê)\s+–Ω–∞–¥\s+(.+?)$', entry, re.IGNORECASE)
    if match:
        return match.group(1).strip().rstrip('.,;')
    
    return None


def _clean_city_name(city: str) -> str:
    if not city:
        return ""
    
    city = city.strip()
    city = re.sub(r'^[üí•üõ∏üõµ‚ö†Ô∏è‚ùóÔ∏èüî¥üöÄ‚úàÔ∏èüëÅÔ∏è‚Ä¢‚ñ™Ô∏è\*\s]+', '', city)
    city = re.sub(r'\([^)]*\)?', '', city).strip()  # Remove incomplete parens too
    city = re.sub(r'[üí•üõ∏üõµ‚ö†Ô∏è‚ùóÔ∏èüî¥üöÄ‚úàÔ∏èüëÅÔ∏è]+', '', city)
    city = re.sub(r'^\d+\s*—Ö?\s*', '', city)
    city = re.sub(r'^(?:–ë–ü–õ–ê|–ë–ø–õ–ê|–ë–ü–õA|—à–∞—Ö–µ–¥[—ñ–∏—ñ–≤]*)\s*', '', city, flags=re.IGNORECASE)
    city = re.sub(r'^(?:–æ—Å—Ç–∞–Ω–Ω—ñ–π|–∫—Ä—É—Ç–∏—Ç—å—Å—è|–∫—Ä—É–∂–ª—è—î|–∫—Ä—É–∂–ª—è—é—Ç—å|–º–∞–Ω–µ–≤—Ä—É—î|–º–∞–Ω–µ–≤—Ä—É—é—Ç—å|–∫—Ä—É—Ç—è—Ç—å—Å—è)\s+', '', city, flags=re.IGNORECASE)
    city = re.sub(r'^(?:–º—ñ–∂|–ø–æ–º—ñ–∂)\s+', '', city, flags=re.IGNORECASE)
    # Clean movement phrases
    city = re.sub(r'^(?:–ø—Ä–æ–¥–æ–≤–∂—É—î\s+—Ä—É—Ö\s+–Ω–∞|—É\s+–Ω–∞–ø—Ä—è–º–∫—É|–≤\s+–Ω–∞–ø—Ä—è–º–∫—É|–Ω–∞|—Ä—É—Ö\s+–Ω–∞)\s+', '', city, flags=re.IGNORECASE)
    city = re.sub(r'^(?:–ª–µ—Ç—è—Ç\s+–≤\s+—Å—Ç–æ—Ä–æ–Ω—É|–ª–µ—Ç–∏—Ç—å\s+–Ω–∞|–ø–æ–∫–∞|–ø–æ–∫–∏)\s+', '', city, flags=re.IGNORECASE)
    # Remove "–≤/—É –ß–æ—Ä–Ω–æ–º—É –º–æ—Ä—ñ" phrases
    city = re.sub(r'\s*[–≤—É]\s+—á–æ—Ä–Ω–æ–º—É\s+–º–æ—Ä[—ñ—é—è].*$', '', city, flags=re.IGNORECASE)
    # Remove trailing movement words
    city = re.sub(r'\s+–∫—Ä—É—Ç—è—Ç—å—Å—è\s*$', '', city, flags=re.IGNORECASE)
    city = re.sub(r'\s+–∑\s+\S+—â–∏–Ω[–∏—ñ—É]?\s*$', '', city, flags=re.IGNORECASE)
    city = re.sub(r'\s+–∑\s+\S+—á—á–∏–Ω[–∏—ñ—É]?\s*$', '', city, flags=re.IGNORECASE)
    city = re.sub(r'\s+–∑\s+—á–æ—Ä–Ω–æ–≥–æ\s+–º–æ—Ä—è\s*$', '', city, flags=re.IGNORECASE)
    city = re.sub(r'\s+–∑\s+–º–æ—Ä—è\s*$', '', city, flags=re.IGNORECASE)
    city = re.sub(r'\s+[–≤—É]\s+–±—ñ–∫\s+.+$', '', city, flags=re.IGNORECASE)
    city = re.sub(r'\s+–∫—É—Ä—Å–æ–º\s+–Ω–∞\s+.+$', '', city, flags=re.IGNORECASE)
    # Remove district suffix "—Ä-–Ω" attached to city name
    city = re.sub(r'—Ä-–Ω\s*$', '', city, flags=re.IGNORECASE)
    # Split glued words like "–û—á–∞–∫—ñ–≤—Å–µ–ª–∞" -> "–û—á–∞–∫—ñ–≤"
    city = re.sub(r'(—ñ–≤|–∫–∞|–∫–∏|–Ω–µ|–∏–Ω|—ñ–≤)(?:—Å–µ–ª–∞|–º—ñ—Å—Ç–∞|—Ä–∞–π–æ–Ω—É|–æ–±–ª–∞—Å—Ç—ñ)\s*$', r'\1', city, flags=re.IGNORECASE)
    # Split CamelCase glued words like "–ì–∞–ª–∏—Ü–∏–Ω–æ–≤–µ–ú–∏–∫–æ–ª–∞—ó" -> take first word "–ì–∞–ª–∏—Ü–∏–Ω–æ–≤–µ"
    camel_match = re.match(r'^([–ê-–Ø–Ü–á–Ñ“ê][–∞-—è—ñ—ó—î“ë\']+)([–ê-–Ø–Ü–á–Ñ“ê][–∞-—è—ñ—ó—î“ë\']+)$', city)
    if camel_match:
        city = camel_match.group(1)  # Take first word only
    if ' —Ç–∞ ' in city:
        city = city.split(' —Ç–∞ ')[0].strip()
    city = city.strip().rstrip('.,;!?')

    city_lower = city.lower()
    # Skip garbage
    if len(city) < 3:
        return ""
    # Skip common non-city words and truncated prefixes
    # Note: removed '–∑–∞–ø' - conflicts with –ó–∞–ø–æ—Ä—ñ–∂–∂—è
    if city_lower in ('–Ω–∞', '–Ω–∞–¥', '–ø—ñ–¥', '–¥–æ', '–≤—ñ–¥', '—á–µ—Ä–µ–∑', '–±—ñ–ª—è', '–∫–æ–ª–æ', '—Ä—É—Ö', '–∫—É—Ä—Å', '–∫—É—Ä—Å–æ–º', '—à—Ç', '–∫–∞–º', '—Å–∞–º', '–¥–Ω—ñ', '—Ö–∞—Ä', '–ø–æ–ª', '–æ–¥–µ', '–º–∏–∫', '–±–µ—Ä–µ–≥–æ–º', '–±–µ—Ä–µ–≥', '–º–æ—Ä–µ', '–º–æ—Ä–µ–º'):
        return ""
    # Skip common nouns that are not cities
    garbage_words = {'–Ω–µ–±–æ', '—Å—Ç–æ–ª–±–∞', '—Å—Ç–æ–ª–±', '–∑–∞—Å—Ç–∞–≤–∞', '–∑–∞—Å—Ç–∞–≤—É', '—Å—Ç–æ—Ä–æ–Ω—É', '–Ω–∞–ø—Ä—è–º–æ–∫', '–Ω–∞–ø—Ä—è–º–∫—É', 
                     '–ø—ñ–≤–Ω—ñ—á', '–ø—ñ–≤–¥–µ–Ω—å', '—Å—Ö—ñ–¥', '–∑–∞—Ö—ñ–¥', '—Ü–µ–Ω—Ç—Ä', '—Ä–∞–π–æ–Ω', '—Å–µ–ª–∞', '–º—ñ—Å—Ç–∞', '–æ–±–ª–∞—Å—Ç—ñ',
                     '—Ä–∞–∫–µ—Ç–∞', '—Ä–∞–∫–µ—Ç–∏', '—Ä–∞–∫–µ—Ç—É', '–¥—Ä–æ–Ω', '–¥—Ä–æ–Ω–∞', '–¥—Ä–æ–Ω–∏', '–±–ø–ª–∞', '—à–∞—Ö–µ–¥', '–∫–∞–±',
                     '–ª–µ—Ç–∏—Ç', '–ª–µ—Ç–∏—Ç—å', '–ª—ñ—Ç–∞—î', '–∫–æ—Å–∏', '–∫–æ—Å—É', '–∫–æ—Å—ñ', '–∫–æ—Å–∞'}
    if city_lower in garbage_words:
        return ""
    if '–Ω–µ–≤–∏–∑–Ω–∞—á–µ–Ω–æ–≥–æ' in city_lower and '—Ç–∏–ø' in city_lower:
        return ""
    if '–±–ø–ª–∞' in city_lower or '—à–∞—Ö–µ–¥' in city_lower:
        return ""
    # Note: removed REGION_ALIASES check - city names like "–ó–∞–ø–æ—Ä—ñ–∂–∂—è" are also cities
    if city_lower.endswith('—â–∏–Ω–∞') or city_lower.endswith('—á—á–∏–Ω–∞') or city_lower.endswith('—â–∏–Ω–∏'):
        return ""
    if '–º–µ–∂—ñ' in city_lower or '–º–µ–∂–∞' in city_lower:
        return ""
    if city_lower.startswith('–∑ '):
        return ""
    # Skip districts (—Ä–∞–π–æ–Ω—É, —Ä–∞–π–æ–Ω)
    if '—Ä–∞–π–æ–Ω' in city_lower:
        return ""
    # Skip region names (–æ–±–ª–∞—Å—Ç—å)
    if '–æ–±–ª–∞—Å—Ç—å' in city_lower:
        return ""
    # Skip phrases not cities
    if '—Ü–µ–Ω—Ç—Ä –æ–±–ª–∞—Å—Ç—ñ' in city_lower or '–º–∞–Ω–µ–≤—Ä' in city_lower:
        return ""
    # Skip geographic features (not settlements)
    if '–∫–æ—Å–∏' in city_lower or '–∫–æ—Å–∞' in city_lower or '–∫–æ—Å—É' in city_lower:
        return ""
    # Skip Russian phrases
    if '—Å—Ç–æ—Ä–æ–Ω—É' in city_lower or '–ª–µ—Ç—è—Ç' in city_lower or '–ø–æ–∫–∞' in city_lower:
        return ""
    # Skip Russian city forms (should be Ukrainian)
    if city_lower.endswith('—Å–∫–∞') or city_lower.endswith('—Å–∫–æ–≥–æ'):
        return ""
    # Skip incomplete words like "–ê—Ä–∏–π" (truncated "–°—Ç–∞—Ä–∏–π")
    if city_lower in ('–∞—Ä–∏–π', '–∞—Ä—ñ–π', '–æ–≤–∏–π', '–∏–π', '—ñ–π'):
        return ""
    if city_lower.startswith('–∞—Ä–∏–π ') or city_lower.startswith('–∞—Ä—ñ–π '):
        return ""

    return city


def _split_cities(content: str) -> List[str]:
    parts = re.split(r'\s*(?:,|\s+—Ç–∞\s+|/)\s*', content)
    filtered = []
    for part in parts:
        if not part:
            continue
        low = part.lower()
        if low in ['—Ä-–Ω', '—Ä-–Ω—É', '—Ä-–Ω–∞', '—Ä–∞–π–æ–Ω', '–æ–∫–æ–ª–∏—Ü—ñ']:
            continue
        if part in REGION_ALIASES or low in REGION_ALIASES_LOWER:
            continue
        filtered.append(part)
    return filtered


def _build_entities_from_city_list(
    cities_text: str,
    region: str,
    count: Optional[int],
    confidence: float,
    pattern: str
) -> List[ExtractedEntity]:
    entities: List[ExtractedEntity] = []
    for city in _split_cities(cities_text):
        if any(dash in city for dash in ['-', '‚Äì', '‚Äî']):
            parts = re.split(r'\s*[-‚Äì‚Äî]\s*', city, maxsplit=1)
            if len(parts) == 2:
                left, right = [c.strip() for c in parts]
                left_norm = normalize_city(left, use_ai=False) or left
                right_norm = normalize_city(right, use_ai=False) or right
                if left_norm in CITIES and right_norm in CITIES:
                    for part in (left_norm, right_norm):
                        entities.extend(_build_entities_from_city_list(
                            part,
                            region,
                            count,
                            confidence,
                            pattern
                        ))
                    continue
        direction_match = PATTERNS.location['v_bik_city'].search(city)
        if direction_match:
            city = direction_match.group(1)
        city = _clean_city_name(city)
        if not city or is_skip_word(city):
            continue
        normalized_city = normalize_city(city)
        resolved_region = region or get_region_for_city(normalized_city, region)
        entities.append(ExtractedEntity(
            city=normalized_city,
            region=resolved_region,
            count=count,
            confidence=confidence,
            pattern_name=pattern
        ))
    return entities


def _is_valid_entity(entity: ExtractedEntity) -> bool:
    if not entity.city or not entity.region:
        return False
    if len(entity.city) < 2:
        return False
    if PATTERNS.direction_words.match(entity.city):
        return False
    if is_skip_word(entity.city):
        return False
    if entity.city in REGION_ALIASES:
        return False
    return True


