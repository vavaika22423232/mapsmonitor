"""
Text normalization - clean and standardize input.
All normalization happens BEFORE parsing.
"""
import re
from typing import Optional
from core.constants import REGION_ALIASES, CITY_CASE_TRANSFORMS, SKIP_WORDS


# Precompiled patterns for normalization
_MARKDOWN = re.compile(r'\*\*|__|~~')
_URLS = re.compile(r'https?://[^\s]+')
_USERNAMES = re.compile(r'@\w+')
_EMOJI_ONLY = re.compile(r'^[âž¡ï¸â¬…ï¸â†—ï¸â†˜ï¸â†–ï¸â†™ï¸â¬†ï¸â¬‡ï¸ðŸ‡ºðŸ‡¦\s|]+$')
_SKIP_LINE = re.compile(
    r'ÐŸÑ–Ð´Ð¿Ð¸ÑÐ°Ñ‚Ð¸ÑÑ|ÐŸÐŸÐžÑˆÐ½Ð¸Ðº|ÐœÐ¾Ð½Ñ–Ñ‚Ð¾Ñ€Ð¸Ð½Ð³ 24/7|Ð Ð°Ð´Ð°Ñ€ Ð£ÐºÑ€Ð°Ñ—Ð½Ð¸|ÐÐ°Ð¿Ñ€ÑÐ¼Ð¾Ðº Ñ€Ð°ÐºÐµÑ‚|ÐšÐ°Ñ€Ñ‚Ð° Ð¿Ð¾Ð²Ñ–Ñ‚Ñ€ÑÐ½Ð¸Ñ… Ñ‚Ñ€Ð¸Ð²Ð¾Ð³|ÐÐµ Ñ„Ñ–ÐºÑÑƒÑ”Ñ‚ÑŒÑÑ|'
    r'Ð—Ð°Ð³Ñ€Ð¾Ð·Ð° Ð´Ð»Ñ .*Ñ€-?Ð²|Ð¿ÐµÑ€ÐµÐ´Ð¼Ñ–ÑÑ‚Ñ–\s+Ñ‡Ð¸ÑÑ‚Ð¾|\bÑ‡Ð¸ÑÑ‚Ð¾\b'
)
_MULTI_SPACE = re.compile(r'\s+')
_EMOJI_PREFIX = re.compile(r'^[ðŸ’¥ðŸ›¸ðŸ›µâš ï¸â—ï¸ðŸ”´ðŸš€âœˆï¸ðŸ‘ï¸ðŸ“¡\*\s]+')
_REGION_SUFFIX = re.compile(r'\s*\([^)]*(?:Ñ‰Ð¸Ð½Ð°|Ñ‡Ñ‡Ð¸Ð½Ð°|Ð¾Ð±Ð»Ð°ÑÑ‚ÑŒ|Ð¾Ð±Ð»\.?)[^)]*\)\s*$', re.IGNORECASE)


def normalize_text(text: str) -> str:
    """
    Clean raw message text for parsing.
    
    Removes:
    - Markdown formatting
    - URLs and usernames
    - Advertisement/channel info lines
    - Excessive whitespace
    
    Args:
        text: Raw message text
        
    Returns:
        Cleaned text ready for parsing
    """
    if not text:
        return ""
    
    # Remove markdown
    text = _MARKDOWN.sub('', text)
    
    # Process line by line
    lines = []
    for line in text.split('\n'):
        line = line.strip()
        
        # Skip empty or whitespace-only
        if not line or line in ['ã…¤', 'â”€' * len(line)]:
            continue
        
        # Skip advertisement lines
        if _SKIP_LINE.search(line):
            continue
        
        # Skip emoji-only lines
        if _EMOJI_ONLY.match(line):
            continue
        
        # Remove URLs and usernames
        line = _URLS.sub('', line)
        line = _USERNAMES.sub('', line)
        
        # Normalize whitespace
        line = _MULTI_SPACE.sub(' ', line).strip()
        
        if line:
            lines.append(line)
    
    return '\n'.join(lines)


def normalize_city(city: str) -> str:
    """
    Normalize city name to nominative case.
    
    Handles:
    - Case transformations (accusative/genitive -> nominative)
    - Emoji removal
    - Prefix cleanup ("Ð Ð°Ð¹Ð¾Ð½", "Ð±Ð¿Ð»Ð°", etc.)
    - Two-word city fixes ("ÐÐ¾Ð²Ñƒ ÐœÐ¸ÐºÐ¾Ð»Ð°Ñ—Ð²ÐºÑƒ" -> "ÐÐ¾Ð²Ð° ÐœÐ¸ÐºÐ¾Ð»Ð°Ñ—Ð²ÐºÐ°")
    
    Args:
        city: Raw city name
        
    Returns:
        Normalized city name in nominative case
    """
    if not city:
        return ""
    
    city = city.strip()
    
    # Remove emoji and special chars
    city = _EMOJI_PREFIX.sub('', city).strip()
    city = re.sub(r'[^\w\s\'\-]', '', city, flags=re.UNICODE).strip()
    
    # Remove prefixes
    city = re.sub(r'^(Ð Ð°Ð¹Ð¾Ð½|Ð±Ð¿Ð»Ð°|Ð‘Ð¿Ð›Ð|Ð‘ÐŸÐ›Ð)\s+', '', city, flags=re.IGNORECASE).strip()
    city = re.sub(r'^Ð½Ð°\s+', '', city, flags=re.IGNORECASE).strip()
    city = re.sub(r'^Ð¡Ñ‚\.?\s*', '', city, flags=re.IGNORECASE).strip()
    
    # Remove region in parentheses from city name
    city = _REGION_SUFFIX.sub('', city).strip()
    
    # Remove suffixes
    city = re.sub(r'\s+Ñ€-Ð½$', ' Ñ€Ð°Ð¹Ð¾Ð½', city, flags=re.IGNORECASE)
    city = re.sub(r'\s+Ñ€$', ' Ñ€Ð°Ð¹Ð¾Ð½', city)
    
    # Remove trailing punctuation
    city = city.rstrip('.!?,;:')
    
    # Check known transformations first
    city_lower = city.lower()
    if city_lower in CITY_CASE_TRANSFORMS:
        return CITY_CASE_TRANSFORMS[city_lower]
    
    # Handle two-word cities ("ÐÐ¾Ð²Ñƒ ÐœÐ¸ÐºÐ¾Ð»Ð°Ñ—Ð²ÐºÑƒ" -> "ÐÐ¾Ð²Ð° ÐœÐ¸ÐºÐ¾Ð»Ð°Ñ—Ð²ÐºÐ°")
    words = city.split()
    if len(words) == 2:
        first, second = words[0], words[1]
        first_fixed = _fix_adjective_case(first)
        second_fixed = _fix_noun_case(second)
        if first_fixed != first or second_fixed != second:
            return f"{first_fixed} {second_fixed}"
    
    # Single word transformations
    return _fix_noun_case(city)


def _fix_adjective_case(word: str) -> str:
    """Fix adjective case (ÐÐ¾Ð²Ñƒ -> ÐÐ¾Ð²Ð°, etc.)"""
    lower = word.lower()
    transforms = {
        'Ð½Ð¾Ð²Ñƒ': 'ÐÐ¾Ð²Ð°', 'ÑÑ‚Ð°Ñ€Ñƒ': 'Ð¡Ñ‚Ð°Ñ€Ð°',
        'Ð²ÐµÐ»Ð¸ÐºÑƒ': 'Ð’ÐµÐ»Ð¸ÐºÐ°', 'Ð¼Ð°Ð»Ñƒ': 'ÐœÐ°Ð»Ð°',
    }
    return transforms.get(lower, word)


def _fix_noun_case(word: str) -> str:
    """Fix noun case to nominative."""
    if not word or len(word) < 3:
        return word
    
    original = word
    lower = word.lower()
    
    # Known transforms
    if lower in CITY_CASE_TRANSFORMS:
        return CITY_CASE_TRANSFORMS[lower]
    
    # Rules for genitive -> nominative
    # -ÐºÐ¸ -> -ÐºÐ° (Ð¡Ð¾Ñ„Ñ–Ñ—Ð²ÐºÐ¸ -> Ð¡Ð¾Ñ„Ñ–Ñ—Ð²ÐºÐ°)
    if lower.endswith('ÐºÐ¸'):
        return word[:-1] + 'Ð°'
    
    # -Ð¾Ð³Ð¾ -> -Ðµ (Ð¡Ð¸Ð½ÐµÐ»ÑŒÐ½Ð¸ÐºÐ¾Ð²Ð¾Ð³Ð¾ -> Ð¡Ð¸Ð½ÐµÐ»ÑŒÐ½Ð¸ÐºÐ¾Ð²Ðµ)
    if lower.endswith('Ð¾Ð³Ð¾') and len(word) > 4:
        return word[:-3] + 'Ðµ'
    
    # Rules for accusative -> nominative
    # -ÐºÑƒ -> -ÐºÐ° (Ð’Ð°ÑÐ¸Ð»ÑŒÐºÑ–Ð²ÐºÑƒ -> Ð’Ð°ÑÐ¸Ð»ÑŒÐºÑ–Ð²ÐºÐ°)
    if lower.endswith('ÐºÑƒ'):
        return word[:-1] + 'Ð°'
    
    # -Ð½Ñƒ -> -Ð½Ð° (ÐŸÑ€Ð¾ÑÑÐ½Ñƒ -> ÐŸÑ€Ð¾ÑÑÐ½Ð°)
    if lower.endswith('Ð½Ñƒ'):
        return word[:-1] + 'Ð°'
    
    # -Ð»ÑŽ -> -Ð»Ñ (Ð¥Ð¾Ñ‚Ñ–Ð¼Ð»ÑŽ -> Ð¥Ð¾Ñ‚Ñ–Ð¼Ð»Ñ)
    if lower.endswith('Ð»ÑŽ'):
        return word[:-1] + 'Ñ'
    
    # -Ð³Ñƒ -> -Ð³Ð°
    if lower.endswith('Ð³Ñƒ'):
        return word[:-1] + 'Ð°'
    
    # Capitalize first letter
    if word and word[0].islower():
        word = word[0].upper() + word[1:]
    
    return word


def normalize_region(region: str) -> Optional[str]:
    """
    Normalize region name to standard format "ÐÐ°Ð·Ð²Ð° Ð¾Ð±Ð»."
    
    Handles:
    - Colloquial names (Ð¥Ð°Ñ€ÐºÑ–Ð²Ñ‰Ð¸Ð½Ð° -> Ð¥Ð°Ñ€ÐºÑ–Ð²ÑÑŒÐºÐ° Ð¾Ð±Ð».)
    - Duplicate "Ð¾Ð±Ð» Ð¾Ð±Ð»." fixes
    - Missing periods
    
    Args:
        region: Raw region name
        
    Returns:
        Normalized region or None
    """
    if not region:
        return None
    
    region = region.strip()
    
    # Check alias mapping first
    if region in REGION_ALIASES:
        return REGION_ALIASES[region]
    
    # Fix double "Ð¾Ð±Ð»"
    region = re.sub(r'\s+Ð¾Ð±Ð»\.?\s+Ð¾Ð±Ð»\.?', ' Ð¾Ð±Ð».', region, flags=re.IGNORECASE)
    
    # Replace "Ð¾Ð±Ð»Ð°ÑÑ‚ÑŒ" with "Ð¾Ð±Ð»."
    region = region.replace(' Ð¾Ð±Ð»Ð°ÑÑ‚ÑŒ', ' Ð¾Ð±Ð».').replace(' ÐžÐ±Ð»Ð°ÑÑ‚ÑŒ', ' Ð¾Ð±Ð».')
    
    # Ensure ends with "Ð¾Ð±Ð»."
    if not region.endswith('Ð¾Ð±Ð».') and not region.endswith('Ð¾Ð±Ð»'):
        if any(x in region.lower() for x in ['ÑÑŒÐºÐ°', 'Ñ†ÑŒÐºÐ°', 'Ð·ÑŒÐºÐ°']):
            region = region.rstrip('.') + ' Ð¾Ð±Ð».'
    
    # Add period if missing
    if region.endswith(' Ð¾Ð±Ð»'):
        region = region + '.'
    
    # Capitalize
    if region:
        region = region[0].upper() + region[1:]
    
    return region


def extract_region_from_alias(text: str) -> Optional[str]:
    """
    Extract region from text containing regional alias.
    
    Args:
        text: Text that may contain region alias (e.g., "Ð¥Ð°Ñ€ÐºÑ–Ð²Ñ‰Ð¸Ð½Ð°")
        
    Returns:
        Normalized region or None
    """
    for alias, region in REGION_ALIASES.items():
        if alias.lower() in text.lower():
            return region
    return None


def is_skip_word(word: str) -> bool:
    """Check if word should be skipped (not a real location)."""
    return word.lower() in SKIP_WORDS
